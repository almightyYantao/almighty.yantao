[["利用 shell 监控磁盘的读写情况","2023年07月07日","/2023/07/08/%E5%88%A9%E7%94%A8-shell-%E7%9B%91%E6%8E%A7%E7%A3%81%E7%9B%98%E7%9A%84%E8%AF%BB%E5%86%99%E6%83%85%E5%86%B5.html/"," 直接附上脚本 使用方式 "],["制作一个内部的 zabbix-agent 快速部署脚本","2023年07月07日","/2023/07/06/%E5%88%B6%E4%BD%9C%E4%B8%80%E4%B8%AA%E5%86%85%E9%83%A8%E7%9A%84-zabbix-agent-%E5%BF%AB%E9%80%9F%E9%83%A8%E7%BD%B2%E8%84%9A%E6%9C%AC.html/"," 下载官方的基础 agent 部署包 官方地址：点击到达 编写 install 脚本 此时的目录下面是这样的结构 在这里你可以编写自定义的监控脚本，毕竟默认的配置文件很多情况下无法满足内部情况 自定义监控案例：TCP 连接情况 新增 Shell 脚本 新增 conf 文件 将这两个文件同时放到你的打包目录下，此时的目录结构是： 修改原来的 install 安装脚本 在自定义脚本的地方加入以下命令： 打包文件 打包好了之后就可以去分发了～ 在客户端安装 agent 服务端 IP：必填 安装目录：可选 agent 路径：可选 端口号：可选 服务检查 开启开机自启 监控图表展示 "],["CentOS 7 安装 Confluence 并且破解","2023年06月06日","/2023/06/16/centos-7-%E5%AE%89%E8%A3%85-confluence-%E5%B9%B6%E4%B8%94%E7%A0%B4%E8%A7%A3.html/"," 简介 Confluence是一个专业的企业知识管理与协同软件，也可以用于构建企业wiki。使用简单，但它强大的编辑和站点管理特征能够帮助团队成员之间共享信息、文档协作、集体讨论，信息推送。部署Confluence前，需确认服务器已部署Nginx+MySQL环境。 搭建环境 系统版本：CentOS Linux release 7.6.1810 (Core) confluence版本：Confluence 7.13.4（最新版本） Java版本： confluence解除工具： 注：解除工具链接: https://pan.baidu.com/s/1po6wouAIZPHbMG39oKKMVw 提取码: guck Mysql-server版本：mysql-community-server.x86_64 0:5.7.22-1.el7​ mysql-connector-java版本：mysql-connector-java-5.1.49 注：以上插件下载地址如下截图可自选【系统版本】和【插件版本】，切记不要使用最新版本插件，由于官网文档说明不支持最新版，然后我特意亲测了一下确实不支持，最大支持mysql-connector-java-5.1.x 高于此版本都不支持，建议使用5.1.x版本插件，插件下载地址： https://downloads.mysql.com/archives/c-j/ 关闭防火墙 禁止防火墙开机自启 关闭 selinux​ 重启系统即可 安装数据库 下载mysql数据库社区yum源 bash vi /etc/my.cnf [mysqld]下添加如下字段 character-set-server=utf8mb4 collation-server=utf8mb4_bin default-storage-engine=INNODB max_allowed_packet=64M innodb_log_file_size=512M transaction-isolation=READ-COMMITTED binlog_format=row log_bin_trust_function_creators = 1 optimizer_switch = derived_merge=off bash systemctl start mysqld systemctl enable mysqld sql create database confluence default character set utf8mb4 collate utf8mb4_bin; grant all on confluence.* to \u0026lsquo;confluence\u0026rsquo;@\u0026rsquo;%\u0026rsquo; identified by \u0026lsquo;Confluence.123\u0026rsquo; with grant option; grant all on confluence.* to \u0026lsquo;confluence\u0026rsquo;@localhost identified by \u0026lsquo;Confluence.123\u0026rsquo; with grant option; flush privileges; bash mkdir /opt/atlassian/ bash mv atlassian-confluence-7.13.5-x64.bin mysql-connector-java-5.1.49-bin.jar atlassian-agent-v1.2.3 /opt/atlassian/ tar xf mysql-connector-java-5.1.49.tar.gz tar xf atlassian-agent-v1.2.3.tar.gz bash chmod +x /opt/atlassian/* ./atlassian-confluence-7.13.5-x64.bin bash lsof -i :8090 bash cp /opt/atlassian/mysql-connector-java-5.1.49/mysql-connector-java-5.1.49-bin.jar /opt/atlassian/confluence/confluence/WEB-INF/lib/ bash yum install java-11-openjdk-devel.x86_64 bash echo -e \u0026lsquo;\\nexport JAVA_OPTS=\u0026quot;-javaagent:/opt/atlassian/atlassian-agent-v1.2.3/atlassian-agent.jar ${JAVA_OPTS}\u0026quot;\\n\u0026rsquo; \u0026raquo; /opt/atlassian/confluence/bin/setenv.sh bash /etc/init.d/confluence restart Confluence 界面配置 本地打开浏览器：http://localhost:8090 修改语言为中文 进行实例安装 获取授权 方式一：保存服务器ID，安装JDK（windows或者Mac） 下载confluence解除工具。将服务器/opt/atlassian/confluence/confluence/WEB-INF/lib/目录下的 atlassian-extras-decoder-v2-3.4.1.jar下载到电脑上。下载文件前一定要先做备份，方便回退。运行解除程序，添加相关信息，先点击「.patch」选择下载下来的文件，然后如下截图一步一步添加字段，最后点击「.gen！」生成解除密钥，复制保存密钥。 方式二：保存服务器ID，安装JDK（linux）返回ssh命令行，使用atlassian-agent生成授权码 授权完成后进行数据库链接即可正常使用！ 注：以上就彻底完成了confluence7.13.4的搭建部署，另外提醒一下这个版本不需要安装中文包，在设置里自带中文设置，直接更改即可。 "],["VSphere VCenter 6.5以上版本安装80%失败处理","2023年05月05日","/2023/05/19/vsphere-vcenter-6.5%E4%BB%A5%E4%B8%8A%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%8580%E5%A4%B1%E8%B4%A5%E5%A4%84%E7%90%86.html/"," 起因 VCenter磁盘满，手贱ssh删除日志后重启失败，选择重装。故障：VC6.5安装卡80%，原因是安装包root密码过期了,root不可用。而且按照提示修改密码一直提示 Th\u0026hellip; 故障 VC6.5安装卡80%，原因是安装包root密码过期了,root不可用。而且按照提示修改密码一直提示 The password change operation failed. 解决 在80%时通过VSClient打开VC宿主虚机（注意要在第一时间打开，而不是已经提示错误。出现错误提示只能重新开始安装而不能继续） 重启在bios时按e进入GNU GRUB Menu 选择linux开头的这一行，在最后添加空格rw init=/bin/bash，然后F10进入 输入mount -o remount,rw / 回车（注意这个”/”别丢了） passwd 两次输入密码，建议用安装时设置的密码 umount /（注意这个”/”别丢了） reboot -f 主要是因为系统版本的问题，网上分享的一般都是： 版本的，这个版本有 BUG，可以换成 "],["解决Nginx SSL 代理 Tomcat 获取 Scheme 总是 Http 问题","2023年05月05日","/2023/05/18/%E8%A7%A3%E5%86%B3nginx-ssl-%E4%BB%A3%E7%90%86-tomcat-%E8%8E%B7%E5%8F%96-scheme-%E6%80%BB%E6%98%AF-http-%E9%97%AE%E9%A2%98.html/"," 背景 公司之前用的是http，但是出于苹果app审核和服务器安全性问题，要改为https，我们公司用的是沃通的ssl，按照沃通的官方文档提供的步骤完成服务器的配置。 架构上使用了 Nginx +tomcat 集群, 且nginx下配置了SSL,tomcat 没有配置SSL,项目使用https协议。 原因 配置成功后明明是https url请求,发现 log里面，tomcat获取scheme的时候，一直是http，而不是想像中的https request.getRequestURL() 输出出来的 一直是 http://m.xxx.com/payment/paymentChannel?id=212\u0026s=a84485e0985afe97fffd7fd7741c93851d83a4f6 但是浏览器中的URL却是 https://m.xxx.com/payment/paymentChannel?id=212\u0026s=a84485e0985afe97fffd7fd7741c93851d83a4f6 下面我们进一步研究发现，java API上写得很清楚: 解决 配置nginx 放到 里面去 其中的 起到了关键性的作用。 配置tomcat 增加到 标签中 配置双方的 X-Forwarded-Proto 就是为了正确地识别实际用户发出的协议是 http 还是 https。 "],["CentOS 7 \u0026 8 开启BBR加速","2023年04月04日","/2023/04/24/centos-7-8-%E5%BC%80%E5%90%AFbbr%E5%8A%A0%E9%80%9F.html/"," CentOS7 一键开启加速脚本 建议安装：BBR魔改加速 CentOS8 开启BBR加速 检测是否开启成功 "],["解决 wg-quick 在 Mac 上 bash 3 无法运行的问题","2023年04月04日","/2023/04/23/%E8%A7%A3%E5%86%B3-wg-quick-%E5%9C%A8-mac-%E4%B8%8A-bash-3-%E6%97%A0%E6%B3%95%E8%BF%90%E8%A1%8C%E7%9A%84%E9%97%AE%E9%A2%98.html/"," 问题原因 我可以理解，开发人员不想使用苹果使用的旧bash v3。但从用户的帖子来看，安装一个较新的bash并不那么好 所以我看了wireguard的wg-quick。需要支持的唯一变化，两个bash版本都是为了摆脱关联数组SERVICE_DNS，并处理v3的BASHPID。 解决方案 那么就有了一下的操作 完整脚本 "],["使用 Python ssh 远程登陆服务器的最佳方案","2023年04月04日","/2023/04/19/%E4%BD%BF%E7%94%A8-python-ssh-%E8%BF%9C%E7%A8%8B%E7%99%BB%E9%99%86%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%96%B9%E6%A1%88.html/","在使用 Python 写一些脚本的时候，在某些情况下，我们需要频繁登陆远程服务去执行一次命令，并返回一些结果。 在 shell 环境中，我们是这样子做的。 然后你会发现，你的输出有很多你并不需要，但是又不去不掉的一些信息（也许有方法，请留言交流），类似这样 对于直接使用 shell 命令，来执行命令的，可以直接使用管道，或者将标准输出重定向到文件的方法取得执行命令返回的结果 1、使用 subprocess 若是使用 Python 来做这件事，通常我们会第一时间，想到使用 os.popen，os.system，commands，subprocess 等一些命令执行库来间接获取 。 但是据我所知，这些库获取的 output 不仅只有标准输出，还包含标准错误（也就是上面那些多余的信息） 所以每次都要对 output 进行的数据清洗，然后整理格式化，才能得到我们想要的数据。 用 举个例子 通过以上的文字 + 代码的展示 ，可以感觉到 ssh 登陆的几大痛点 痛点一：需要额外安装 sshpass（如果不免密的话） 痛点二：干扰信息太多，数据清理、格式化相当麻烦 痛点三：代码实现不够优雅（有点土），可读性太差 痛点四：ssh 连接不能复用，一次连接仅能执行一次 痛点五：代码无法全平台，仅能在 Linux 和 OSX 上使用 2、使用 paramiko 带着最后一丝希望，我尝试使用了 这个库，终于在 这里，找回了本应属于 Python 的那种优雅。 你可以通过如下命令去安装它 方法1：基于用户名和密码的 sshclient 方式登录 方法2：基于用户名和密码的 transport 方式登录 方法3：基于公钥密钥的 SSHClient 方式登录 方法4：基于密钥的 Transport 方式登录 以上四种方法，可以帮助你实现远程登陆服务器执行命令，如果需要复用连接：一次连接执行多次命令，可以使用 方法二 和 方法四 用完后，记得关闭连接。 实现 sftp 文件传输 同时， 做为 ssh 的完美解决方案，它非常专业，利用它还可以实现 文件传输。 参考链接 https://github.com/paramiko/paramiko http://docs.paramiko.org https://www.liujiangblog.com/blog/15/ "],["hugo + github自动化部署静态博客","2023年04月04日","/2023/04/18/hugo--github%E8%87%AA%E5%8A%A8%E5%8C%96%E9%83%A8%E7%BD%B2%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2.html/"," 背景 在使用hugo + nginx搭建好博客后，文章可以通过ftp上传到服务器，然后在服务器上再编译成网页，或者本地搭建的hugo环境，编译好网页再上传到服务器，这样做虽然也可以，但是很麻烦，如果每次都这么发布文章，肯定玩几次就不想弄了。 使用webhook就能实现自动部署，其实原理很简单。理想状态就是我把我的myblog项目托管到github，然后每次我写完文章直接push到github仓库，webhook监听到我的push，给我的服务器发送一个http请求，服务器收到请求后执行本地shell脚本，自动拉取最新的仓库代码，然后执行hugo编译成网页。这样就实现自动部署啦! 服务器环境配置 node 我是centos系统，直接安装编译好的二进制文件了，之前试过自己编译，要等好久就放弃了 安装完后可以执行以下命令检查： pm2 项目代码托管到github 在常用的本地机器上安装git，myblog 目录作为 git 仓库，push 到 github 进行备份。由于 public 目录下的静态网页完全可由其余文件自动生成，因此仓库可以排除 public 目录。 Github配置SSH Key GitHub配置SSH Key的目的是为了帮助我们在通过git拉取代码时，不需要繁琐的验证用户名密码，如果需要验证，我们的自动脚本就挂了。 首先检查是否存在sshkey 如果没有则执行如下命令，然后回车到底 最后获取sshkey填入github配置中（点击右上角头像，settings，找到ssh点进去取个名字复制下即可。） 配置shell脚本 编写js脚本 先安装一个第三方插件 两个脚本最好放在一个目录下面，然后目前因为整体的方式是通过SSH拉取代码下来，你可以改成拉取所有的文件，然后在服务器里面hugo编译，也可以本地hugo，然后服务器只拉取public的文件，这个随意，看着改就行。 点击右上角Settings按钮，选择Webhooks，点击右上角Add wehook ：http://你的域名:7777/webhook ：application/json ：mysecret 到此，所有配置就结束了，可以在本机上push到仓库，服务器就会自动编译网站了。(#.#) "],["通过iptables进行wireguard的权限管理","2023年04月04日","/2023/04/18/%E9%80%9A%E8%BF%87iptables%E8%BF%9B%E8%A1%8Cwireguard%E7%9A%84%E6%9D%83%E9%99%90%E7%AE%A1%E7%90%86.html/"," 一、背景 由于目前openvpn的开源方案，链接VPN如果路由过多的话会导致链接速度变慢，效果非常的不理想，并且当iptables规则多的时候，转发明显性能下降； 准备采用wireguard的方式来代替openvpn的隧道协议，但是wireguard目前没有一个很好的权限管理方案； 二、服务端 2.1、安装wireguard 2.2、设置访问权限 环境变量： 可以获取连接着的IP地址 然后在根据情况设置ipset和iptables 2.3、脚本案例 2.4、常用脚本变量 : Wireguard 公钥。默认值为 $HOME/.wireguard/wg0.key. : Wireguard 私钥。默认值为 $HOME/.wireguard/wg0.pem. : Wireguard 服务 IP 地址。默认值为 127.0.0.1. : Wireguard 服务端口。默认值为 9443. : 设备的 IP 地址。默认值为 127.0.0.1. : 设备的端口。默认值为 9443. : Wireguard 网络名称。默认值为 mywireguard. : Wireguard 通道名称。默认值为 channel0. : Wireguard 控制页面 URL。 : Wireguard 通道的 peer DNS 名称。默认值为 mywireguard.com. : Wireguard 通道的 peer IP 地址。默认值为 192.168.0.100. : Wireguard 通道失败时的处理方式。默认值为 continue. : Wireguard 控制页面 URL。 : Wireguard 私钥。默认值为 $HOME/.wireguard/wg0.pem. : Wireguard 公钥。默认值为 $HOME/.wireguard/wg0.key. : 设备的 IP 地址。默认值为 127.0.0.1. : 设备的端口。默认值为 9443. : Wireguard 网络名称。默认值为 mywireguard. : Wireguard 通道名称。默认值为 channel0. : Wireguard 控制模式 (0 表示禁用，1 表示启用)。默认值为 0. 三、客户端 3.1、二进制文件 我对 的评价 : https://www.123pan.com/s/cRk7Vv-NLSsH.html 提取码:2Zcc : https://github.com/WireGuard/wireguard-tools/blob/master/src/wg-quick/darwin.bash "],["linux通过SNMP检测TCP\u0026UDP连接数","2023年03月03日","/2023/03/11/linux%E9%80%9A%E8%BF%87snmp%E6%A3%80%E6%B5%8Btcpudp%E8%BF%9E%E6%8E%A5%E6%95%B0.html/"," 先上图\u0026amp;介绍 记录一次全球化网络监控的看板建设； 之前都是通过zabbix来进行建设看板，但是用了一段时间后总是缺点感觉；后面通过大佬的介绍，试用了 ，这不试用还好，一试用，效果的展现让我无法自拔，这就是我想要的监控看板啊！能根据数值的不同进行颜色的区分，在大屏上一眼就可以看出当前哪一块网络出现了问题！ 美中不足的是，上面的两列不能设置报警，报警貌似必须是图表形式的才可以；不过可以建立一个通用的报警看板，问题不大～ 其他的一些监控项都是最简单基础的，我这边就不过多的赘述，大家可以自行上网搜索，或者之前引用之前 的数据，主要讲解下 和 的获取 别的不说，这图还是很好看的； 准备 SNMP 自定义OID snmp安装 修改配置文件 创建获取连接数脚本 这个是获取 连接数的脚本，如果要获取UDP的，请把 改成 设置脚本权限 修改SNMP配置文件 文件路径： 在最底下加入这条命令，后面的 脚本就是上传创建的脚本路径 重启SNMP服务 后记 通过这种方式，我们就可以做更多的扩展，比如 获取连接人数 当前访问情况 \u0026hellip; "],["Obsidian 免费的实时同步服务","2023年03月03日","/2023/03/06/obsidian-%E5%85%8D%E8%B4%B9%E7%9A%84%E5%AE%9E%E6%97%B6%E5%90%8C%E6%AD%A5%E6%9C%8D%E5%8A%A1.html/","使用 fly.io 免费计划部署或自托管数据库，进行 LiveSync 插件的一系列配置后实现各设备间 Obsidian 实时增量修改同步，可以和官方同步服务相媲美。 使用 fly.io 这次使用的是 fly.io 的免费计划，fly.io 是一个 SAAS（是（Platform as a Service）的缩写，是指平台即服务）平台，可以搭建如静态博客、Nextjs、Nuxtjs、Deno、Go、Python 等底层的各种各样的服务。但首先需要自己注册一个账号，这里可以直接使用 Github 登录。 注意：fly.io 的使用需要绑卡，如果没有绑卡会在创建应用 章节出现 Error 提示。绑卡过程请在 fly.io 面板 中 Billing 进行。正常使用国内的双币卡就可以，注意请如实填写信息。没有卡的朋友可以去各银行办一张（超好过的😗）或试试虚拟卡？（虚拟卡只是博主想到的一种方案，没有试过） 安装 flyctl Windows 用户在本地打开 PowerShell 或 Windows 终端💻，输入： 注意：CMD 中不支持上面的命令，如果电脑中只有 CMD，或许你需要安装 PowerShell （选择 latest 版本）或 Windows 终端 。 本地登录 会自动打开浏览器进行验证账户操作。 创建应用 在本地任意位置创建一个 fly.io 的工作目录（其实就是创建个能找到的文件夹，你不会放桌面上了吧😂？）。 进入 couchdb 目录后输入命令： 这一步将会启动一个向导，按自己的需求进行选择。 Select region 的意思是选择一个位置，尽量选择靠近自己的位置。 配置卷大小 我输入的配置卷大小命令为： nrt 的意思是东京地区，你需要改变为和上面选择的位置区域 一样的位置代码。这一行命令的意思是：在东京地区创建一个 1G 大小的卷。 调整配置信息 打开应用根目录的 文件，添加或修改如下信息： 根目录为在创建应用 章节中创建的新文件夹 couchdb 博主是全部配置完毕后写这篇文章的😎，所有可能有遗漏或一些错误？为了保证严谨性，把自己的配置全部贴一份做对照吧： 请对比上面提供的配置文件修改自己的 fly.toml 文件。 设置密码 在终端中输入命令： 注意：密码使用大小写字母与数字，不要使用特殊字符。实际测试后发现使用特殊字符时无法识别密码，会无法登录数据库。 如果想要修改密码，可以再次运行上面的命令。 部署 注意，如果提示 Services defined at indexes: 0 require a dedicated IP address. You currently have no dedicated IPs allocated. Please allocate at least one dedicated IP before deploying，那么需要运行 。 在终端中输入命令： 稍作等待后提示部署成功🎉。使用下面命令可以打开网页登录： 如果是 fly.io 部署，那么在网址后加 ，跳转后可以输入用户名与密码。 网页成功登录，好耶🎉 网页数据库配置 这一大章节都在网页中进行。如果不知道自己的地址，可以打开 fly.io 面板 ，点击自己的应用， 处为自己应用的网址。 创建数据库 点击右上角的 ，创建一个数据库， 为数据库名字， 请不要勾选，然后点 创建。 配置其他信息 打开 选项卡，填写相关信息。 第一行的 为你在上面步骤中配置的用户信息。第二行的 意思是监听的访问地址，设置为 为允许所有 ip 访问。第三行的 为你在 调整配置信息 这一步中的 文件中配置的端口，如果和我设置的一样，那这里应该是 😚。设置完成后会显示 ，代表配置成功。 启用 CORS 然后打开 选项卡中的 标签，启用 CORS。完成网页端操作！ 下方的 Origin Domains 需要设置为 。 Obsidian 设置 这一章节的操作都在 Obsidian 本体软件中进行。首先需要关闭 Obsidian 中的安全模式，在插件市场中搜索 下载并启用。在 Github 仓库中手动下载安装本插件可能会出现一些问题。 在移动端可能会打不开插件市场，是众所周知的网络原因，需要自己解决😑。 配置连接信息 打开 选项卡。输入自己的数据库网址、用户名、密码与数据库名。 数据库网址 URI 为 的形式，如果找不到可以使用 或在 fly.io 面板 中打开自己的应用查看 Hostname 项。 用户名与密码为在调整配置信息 时填写的用户名与在设置密码 中用命令设置的密码。 数据库名为在创建数据库 时创建的数据库名。 ### 修复连接 点击 ，在右上角出现 Connect to 数据库名，则为连接成功。然后点击 ，会出现一堆日志，逐个点击后面的 按钮修复即可。 修复完成后重新点击 ，没有出现 按钮即为修复成功。 同步设置 打开 Sync Settings 选项卡，其中有所有的同步方式设置。注意：实时同步 (LiveSync) 与定时同步 (Periodic Sync) 互斥，无法同时打开。 可能有朋友会纠结用哪个，在这里强烈推荐使用 LiveSync（实时同步）方式，毕竟用此插件就是为了这个。因为 Periodic Sync（定时同步）中包含有 Sync on Save (保存时同步)、Sync on File Open (文件打开时同步)、Sync on Start (打开软件时同步) 各种选项，合计一下完全就是变相的实时同步嘛！第二点是当我使用 开启本地博客变更监听后发现，Obsidian 会自动在输入文字后保存一次，造成频繁的 Sync on Save (保存时同步) 操作。所以，还是使用 LiveSync（实时同步）吧👍。 其他设置 在 Sync Settings 选项卡中还包含有 （删除文件到回收站）配置强烈建议打开，防止文件意外丢失。 在 Miscellaneous 选项卡（一个小扳手图标）中，有选项 （在编辑器右上角显示当前同步状态），推荐打开。 同步状态将显示在状态栏，状态都有： ⏹️ 准备就绪 💤 LiveSync 已启用，正在等待更改 ⚡️ 同步中 ⚠️ 出现错误 信息解释： ↑ 上传的 chunk 和元数据数量 ↓ 下载的 chunk 和元数据数量 ⏳ 等待的过程的数量 🧩 正在等待 chunk 的文件数量 如果你删除或修改了文件名称，请等待 ⏳ 图标消失。 安装于其他设备 在插件 Setup wizard 选项卡中，点击 ，弹出的对话框输入你的数据库密码，即可复制当前的配置信息。在其他如 Android、iOS 设备上安装此插件并点击 输入复制的链接即可。 在这里选第一个，意思为将此设备设置为辅助或后续设备。稍等一会儿后即可同步完成。而且同步非常快，只需要几秒钟就好。 这里放一张官网的同步动态图可以感受一下。 推荐方案 值得注意的是，不应该在 Obsidian 中存放太多媒体文件，如：Markdown 文件直接引用本地图片或音频。不然会显著拖慢任何 WebDAV 或 LiveSync 的同步速度。做一个对比，我的 Obsidian 中大概有 80 篇左右笔记与博文，本地源文件只有 600KB，数据库占用只有 2MB 左右。如果使用本地引用图片，那么一张图片就能抵得上我全部笔记的大小，同步时间将成倍的增长🙄。所以，这些媒体文件更应该放入图床或对象存储中，使用 的形式引用。 后记 fly.io 部署的服务体验太好了💖。Obsidian 各端同步起来非常快，虽然看面板只是一个 256MB 的小机器，但是这个任务完全可以胜任。fly.io 每个账户的免费资源包括：总共 3GB 的卷、最多 3 个共享 CPU-1x 256MB 虚拟机、每月 160GB 出站数据传输。看起来还能做一些新玩法的样子。在对比使用 Remotely save 同步后发现，同步速度除了快就是快，刚在电脑上写完一句话，想起有事情准备走，拿起手机打开 Obsidian，完全可以接着继续编辑，无缝同步的体验真是太棒了！我宣布这是 Obsidian 非官方同步服务的最佳方式。 "],["通过 Haproxy 实现 Shadowshadows 负载均衡","2023年03月03日","/2023/03/05/%E9%80%9A%E8%BF%87-haproxy-%E5%AE%9E%E7%8E%B0-shadowshadows-%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1.html/"," 介绍 缺点：所有的SS的加密方式和密码必须一致 介绍：HAProxy是一个使用C语言编写的自由及开放原始码软件，其提供高可用性、负载均衡，以及基于TCP和HTTP的应用程序代理。 安装Haproxy 配置 ：后面首先跟名字，名字随便起呗，自己能够区分就行。紧接着跟SS的公网IP+端口，端口也就是SS/SSR的端口。 ：是检测的意思，这段配置很重要 ：单位毫秒，我配置的500，即500毫秒检测一次目标服务器。 ：设定健康状态检查中，某离线的服务器从离线状态转换至正常状态需要成功检查的次数，这里我设置的2次。 ：确认服务器从正常状态转换为不可用状态需要检查的次数，这里是4次。 ：权重，值越大代表这台机器工作的机会越多，这里我们可以把一台线路较好的机器的权重设置高一些。 ：负载均衡方式 roundrobin：基于权重进行轮叫，在服务器的处理时间保持均匀分布时，这是最平衡、最公平的算法。此算法是动态的，这表示其权重可以在运行时进行调整，不过，在设计上，每个后端服务器仅能最多接受4128个连接； static-rr：基于权重进行轮叫，与roundrobin类似，但是为静态方法，在运行时调整其服务器权重不会生效；不过，其在后端服务器连接数上没有限制； leastconn：新的连接请求被派发至具有最少连接数目的后端服务器；在有着较长时间会话的场景中推荐使用此算法，如LDAP、SQL等，其并不太适用于较短会话的应用层协议，如HTTP；此算法是动态的，可以在运行时调整其权重； source：将请求的源地址进行hash运算，并由后端服务器的权重总数相除后派发至某匹配的服务器；这可以使得同一个客户端IP的请求始终被派发至某特定的服务器；不过，当服务器权重总数发生变化时，如某服务器宕机或添加了新的服务器，许多客户端的请求可能会被派发至与此前请求不同的服务器；常用于 负载均衡无cookie功能的基于TCP的协议；其默认为静态，不过也可以使用hash-type修改此特性； 修改Shadowsocks配置 "],["OpenWrt多拨使用教程","2023年02月02日","/2023/02/28/openwrt%E5%A4%9A%E6%8B%A8%E4%BD%BF%E7%94%A8%E6%95%99%E7%A8%8B.html/"," 多拨类 多拨相关的插件主要是 多线多拨 和 负载均衡 插件。 Syncdial 多线多拨 使用macvlan驱动创建多个虚拟WAN口，支持并发多拨 MWAN3负载均衡 支持多根网线或者多个PPPOE账号的同时拨号使用和负载均衡。并且还可以通过Ping方式来检测中断线路并自动屏蔽中断线路 其他 如发现无法安装或更新，请执行以下操作 更新OPKG软件列表 "],["Python ChatGPT Telegram Bot","2023年02月02日","/2023/02/21/python-chatgpt-telegram-bot.html/"," 注册 这里如何注册我就不说明了，大家自行去注册，主要是现在GPT的基本上已经备用很多了，导致了接码的价格也上涨了，而且使用token的话，其实还是很快可以用完免费的18美金； 接码：https://sms-activate.org/ 准备材料 主要提供下Python的实现代码，首先需要准备一下的东西： Telegram Bot 的 Key ：找机器人爸爸获取 ChatGPT 的 API Key ： https://platform.openai.com/account/api-keys 脚本： {% codeblock \u0026ldquo;main.py\u0026rdquo; lang:python \u0026gt;folded %} 1. Start by importing the necessary libraries and setting up the API clients import requests import json import os import threading OpenAI secret Key API_KEY = \u0026lsquo;xxxxxxxxx\u0026rsquo; Models: text-davinci-003,text-curie-001,text-babbage-001,text-ada-001 MODEL = \u0026rsquo;text-davinci-003' Telegram secret access bot token BOT_TOKEN = \u0026lsquo;xxxxxxxxxxxxx\u0026rsquo; Defining the bot\u0026rsquo;s personality using adjectives BOT_PERSONALITY = '' 2a. Function that gets the response from OpenAI\u0026rsquo;s chatbot def openAI(prompt): # Make the request to the OpenAI API response = requests.post( \u0026lsquo;https://api.openai.com/v1/completions' , headers={\u0026lsquo;Authorization\u0026rsquo;: f\u0026rsquo;Bearer {API_KEY}\u0026rsquo;}, json={\u0026lsquo;model\u0026rsquo;: MODEL, \u0026lsquo;prompt\u0026rsquo;: prompt, \u0026rsquo;temperature\u0026rsquo;: 0.4, \u0026lsquo;max_tokens\u0026rsquo;: 4000} ) result = response.json() print(result) final_result = ''.join(choice['text'] for choice in result['choices']) return final_result 2b. Function that gets an Image from OpenAI def openAImage(prompt): # Make the request to the OpenAI API resp = requests.post( \u0026lsquo;https://api.openai.com/v1/images/generations' , headers={\u0026lsquo;Authorization\u0026rsquo;: f\u0026rsquo;Bearer {API_KEY}\u0026rsquo;}, json={\u0026lsquo;prompt\u0026rsquo;: prompt, \u0026rsquo;n\u0026rsquo;: 1, \u0026lsquo;size\u0026rsquo;: \u0026lsquo;1024x1024\u0026rsquo;} ) response_text = json.loads(resp.text) return response_text['data'][0]['url'] 3a. Function that sends a message to a specific telegram group def telegram_bot_sendtext(bot_message, chat_id, msg_id): data = { \u0026lsquo;chat_id\u0026rsquo;: chat_id, \u0026rsquo;text\u0026rsquo;: bot_message, \u0026lsquo;reply_to_message_id\u0026rsquo;: msg_id } response = requests.post( \u0026lsquo;https://api.telegram.org/bot' + BOT_TOKEN + \u0026lsquo;/sendMessage\u0026rsquo;, json=data ) return response.json() 3b. Function that sends an image to a specific telegram group def telegram_bot_sendimage(image_url, group_id, msg_id): data = { \u0026lsquo;chat_id\u0026rsquo;: group_id, \u0026lsquo;photo\u0026rsquo;: image_url, \u0026lsquo;reply_to_message_id\u0026rsquo;: msg_id } url = \u0026lsquo;https://api.telegram.org/bot' + BOT_TOKEN + \u0026lsquo;/sendPhoto\u0026rsquo; response = requests.post(url, data=data) return response.json() 4. Function that retrieves the latest requests from users in a Telegram group, generates a response using OpenAI, and sends the response back to the group. def Chatbot(): # Retrieve last ID message from text file for ChatGPT update cwd = os.getcwd() filename = cwd + \u0026lsquo;/chatgpt.txt\u0026rsquo; if not os.path.exists(filename): with open(filename, \u0026ldquo;w\u0026rdquo;) as f: f.write(\u0026ldquo;1\u0026rdquo;) else: print(\u0026ldquo;File Exists\u0026rdquo;) with open(filename) as f: last_update = f.read() # Check for new messages in Telegram group url = f'https://api.telegram.org/bot{BOT_TOKEN}/getUpdates?offset={last_update}' response = requests.get(url) data = json.loads(response.content) for result in data['result']: try: # Checking for new message if float(result['update_id']) \u0026gt; float(last_update): # Checking for new messages that did not come from chatGPT if not result['message']['from']['is_bot']: last_update = str(int(result['update_id'])) # Retrieving message ID of the sender of the request msg_id = str(int(result['message']['message_id'])) # Retrieving the chat ID chat_id = str(result['message']['chat']['id']) # Checking if user wants an image if '/img' in result['message']['text']: prompt = result['message']['text'].replace(\u0026quot;/img\u0026quot;, \u0026quot;\u0026quot;) bot_response = openAImage(prompt) print(telegram_bot_sendimage(bot_response, chat_id, msg_id)) # Checking that user mentionned chatbot's username in message if '@chatGpt_dandelion_bot' in result['message']['text'] \\ or '/ask' in result['message']['text']: prompt = result['message']['text'].replace(\u0026quot;@chatGpt_dandelion_bot\u0026quot;, \u0026quot;\u0026quot;) # Calling OpenAI API using the bot's personality bot_response = openAI(f\u0026quot;{BOT_PERSONALITY}{prompt}\u0026quot;) # Sending back response to telegram group print(telegram_bot_sendtext(bot_response, chat_id, msg_id)) # Verifying that the user is responding to the ChatGPT bot if 'reply_to_message' in result['message']: if result['message']['reply_to_message']['from']['is_bot']: prompt = result['message']['text'] bot_response = openAI(f\u0026quot;{BOT_PERSONALITY}{prompt}\u0026quot;) print(telegram_bot_sendtext(bot_response, chat_id, msg_id)) except Exception as e: print(e) # Updating file with last update ID with open(filename, 'w') as f: f.write(last_update) return \u0026quot;done\u0026quot; 5 Running a check every 5 seconds to check for new messages def main(): timertime = 5 Chatbot() # 5 sec timer threading.Timer(timertime, main).start() Run the main function if name == \u0026ldquo;main\u0026rdquo;: main() {% endcodeblock %} "],["curl 检测代理的可用性以及延迟","2023年02月02日","/2023/02/20/curl-%E6%A3%80%E6%B5%8B%E4%BB%A3%E7%90%86%E7%9A%84%E5%8F%AF%E7%94%A8%E6%80%A7%E4%BB%A5%E5%8F%8A%E5%BB%B6%E8%BF%9F.html/"," 背景 在办公网的代理翻墙的过程中，经常没办法第一时间知道代理失效了，因为我们自身不是高用的用户，每次挂了都需要员工来反馈，体感非常的不好，因此想着可以通过 如果把当前的延迟、可用性检测起来 通过Curl 检测Google的延迟 这里为啥是curl而不是ping，因为默认ping事不支持代理的，然而curl也可以做到真正的是否可用 的地址需要改成你的代理地址 bash url=$1 result=($(curl -x socks5h://localhost:12126 -I -s \u0026ndash;connect-timeout 5 ${url} | head -1 | tr \u0026ldquo;\\r\u0026rdquo; \u0026ldquo;\\n\u0026rdquo;)) if [ \u0026ldquo;${result[1]}\u0026rdquo; == $2 -a \u0026ldquo;${result[2]}\u0026rdquo; == \u0026lsquo;OK\u0026rsquo; ] then echo 1 else echo 0 fi bash 延迟 UserParameter=googleTime[*],/etc/zabbix/script/googleTime.sh $1 可用 UserParameter=googleCheck[*],/etc/zabbix/script/googleCheck.sh $1 $2 "],["记录一次办公网全球化的改造计划","2023年02月02日","/2023/02/17/%E8%AE%B0%E5%BD%95%E4%B8%80%E6%AC%A1%E5%8A%9E%E5%85%AC%E7%BD%91%E5%85%A8%E7%90%83%E5%8C%96%E7%9A%84%E6%94%B9%E9%80%A0%E8%AE%A1%E5%88%92.html/"," 背景 办公网每次去海外找资料都需要重新连接VPN，或者自己连接自己买的小飞机之类的才可以。但是这种在互联网公司内的话，非常的不友好；为公司工作还要自己花钱买小飞机～ 之前尝试过下面这种方式： 新增一台海外的机器（新加坡、香港）搭建SS/v2ray/trojan之类的协议，然后办公网新增一个软路由去连接，通过ACL把部分IP的用户跳转过去； 但是这种方式自己家里用用还行，如果想要在企业的办公网来使用的话，人一多就不行，因为所有人都从这个IP出去了，而且每次都需要命令行去操作ACL增加用户，非常的麻烦； Panabit 的 iWAN 为了解决前面的这种方式，决定测试使用 Panabit 的 Iwan 的方式，也就是所谓的 Panabit 的 ； 重连速度很快： 比L2TP的要快一个数量级，L2TP要重连，需要有几十次交互，而我们只需要一次即可 客户端不受底层承载线路IP变化影响： 当底层承载线路（比如PPPOE拨号线路）的IP地址发生变化时，不会影响iWAN隧道，iWAN隧道不会中断，保证通信正常进行； 因为很多用户是通过PPPOE拨号线路出去的，PPPOE拨号线路重拨时一般会改变IP地址，如果用L2TP的话，那么这个L2TP会话就要重建； 而用iWAN的话，现有的会话可以照常使用，不需要做任何改变； 传输效率高： iWAN的包头很小，只有8个字节，而且在后续版本里，我们会压缩IP报文头，这样可以继续减少额外报文头的大小，所以能大幅度提升传输效率； 如果用国际线路的话，节省下来的流量费用都是很可观的； 抗干扰： 不像L2TP，中间人可以直接发包TERMINATE，iWAN控制命令有完整性检查，可以避免中间人攻击。 部署 1、搭建panabit 记得服务器申请2H的，1H需要需改核心，非常麻烦 下载Linux系统文件：文末 上传文件到root根目录下 修改 文件 因为是单网口，所以数据口和管理口都需要配置成eth0，后面不要加任何东西 修改端口 上传文件，修改配置 需要上传一个joskmc文件（文件在文末） 在 中新增一下一行 执行joskmc 修改： ，增加一下三行 2、进行隧道配置（海外） (1)、登录WEB页面，修改网卡方向 默认账号密码：admin/panabit 系统概况 → 网络接口：eth0，修改成对外，只有对外才可以创建WAN线路 (2)、创建WAN线路 应用路由 → 接口线路： 需要注意，Mac地址必须克隆 (3)、创建IWAN连接账号 对象管理 → 账号管理 → 组织架构： 地址范围：这一块可以自己定一个内网的IP段就可以，不要冲突就好 地址范围需要把网关地址留出来！！！！！ 对象管理 → 账号管理 → 本地账号： 处理用户组需要选择前面创建的用户组，其他的根据实际情况填写 (4)、创建iWAN服务 应用路由 → iWAN服务 → 服务列表： 注意：服务器网关地址要和你前面设置的地址范围要在一块，并且需要排除这个地址的下发 应用路由 → iWAN服务 → 服务映射： 根据配置情况选择即可 iWAN使用的是UDP连接，因此端口需要开放UDP (5)、创建策略路由 应用路由 → 策略路由：需要添加一条回程的全程路由，要不然DNS牵引、FQ都会失败 这里选择iWAN的线路 3、客户端配置（办公网） (1)、新建WAN线路 应用路由 → 接口线路 → WAN线路：按照信息提示填写即可完成iWAN线路配置 注意：必须有一个外网的网卡，并且最好把加密开起来 (2)、设置DNS牵引 应用路由 → DNS管控：海外域名是一个域名群组，可以自己修改 主要解决DNS污染问题，要不然可能部分网站会无法访问 这里有一个很注意的点，就是你的DNS，访问DNS的链路必须经过PA，否则牵引不会生效 (3)、设置策略路由 应用路由 → 策略路由：我这边直接拿了飞连的609海外分流IP段进行分流，你也可以自己修改（文末下载） 主要为了只有需要海外的才出去，不能把所有的流量全部导出去 附件 169IP段： https://www.123pan.com/s/cRk7Vv-frSsH 提取码:NzAF Linux操作系统： https://www.123pan.com/s/cRk7Vv-arSsH 提取码:A5MC joskmc： https://www.123pan.com/s/cRk7Vv-BrSsH 提取码:kTu9 "],["清理自定义DHCP下发，异常断开导致IP地址占用的问题","2023年02月02日","/2023/02/16/%E6%B8%85%E7%90%86%E8%87%AA%E5%AE%9A%E4%B9%89dhcp%E4%B8%8B%E5%8F%91%E5%BC%82%E5%B8%B8%E6%96%AD%E5%BC%80%E5%AF%BC%E8%87%B4ip%E5%9C%B0%E5%9D%80%E5%8D%A0%E7%94%A8%E7%9A%84%E9%97%AE%E9%A2%98.html/"," 背景 因为OpenVpn存在断开重连的机制，如果突然出现网络抖动，用户端没有触发断开命令，但是同时又触发了重新连接的命令，这时候VPN这里就会重新给下发一个新的地址，但是老的地址不会回收掉，这个也是很早之前DHCP被用完的真正原因 处理方式 在每一台openvpn的机器上新增一个shell脚本做定时任务，每天临晨2点开始循环遍历 "],["zabbix 警报推送至企业微信（图文版）","2023年02月02日","/2023/02/05/zabbix-%E8%AD%A6%E6%8A%A5%E6%8E%A8%E9%80%81%E8%87%B3%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E5%9B%BE%E6%96%87%E7%89%88.html/"," 新增Python脚本 新增SH脚本 把两个文件都放到这个目录下：/usr/lib/zabbix/alertscripts/ 配置媒介 "],["安装\u0026破解Openvpn Access Server","2023年01月01日","/2023/01/05/%E5%AE%89%E8%A3%85%E7%A0%B4%E8%A7%A3openvpn-access-server.html/"," 在线安装（需要翻墙） 管理员登录 首先需要修改管理员密码 输入之后可以登录管理员页面了。 如果密码一直错误的话，说明修改失败了，可以查看下原来的密码是什么 登录后点击User Management–\u0026gt;User Permissions 添加用户 破解用户数 主要操作的文件是一个名叫 的文件，以我了解的情况来看，从 到 文件名一直都是这个，只是不同版本里面的内容不一样. 这个文件有点类似 当中的 库文件，也是一个 压缩文件，里面包含了一些 的字节码文件. 破解的原理大概是在 中采用类似 动态代理的技术，将原本读取用户属性的调用返回值拦截，修改用户限制数量再返回. 方法 以下版本破解的目标文件是 , 及以上是 ; 按照网上流行的破解方法，把这个文件解压出来并改名为 或 , 然后新建一个 文件，内容如下: 以下版本内容: 及以上版本内容: 再将上面的 编译为库文件 或 : 注意 文件名会随着 版本变化而变化. 现在我们得到了一个改文件名的文件 或 , 和一个编译出来的 或 ; 把这两个文件压缩到 的 目录下，然后去服务器替换目标文件，重启服务就 OK 了. 所有的操作命令 "],["openvpn动态下发权限","2022年12月12日","/2022/12/14/openvpn%E5%8A%A8%E6%80%81%E4%B8%8B%E5%8F%91%E6%9D%83%E9%99%90.html/"," 首先了解我们为什么要动态下发 开源的openvpn并不支持权限管理，大部分在做权限管理的时候使用的都是根据来源IP或IP段通过iptables/交换机来进行权限控制 权限控制太广了，根本无法很好的去做管理后台的配置，特别是需要用户组来进行区分的时候，那就更困难了 权限下发的逻辑 {% plantuml %} title openvpn连接示意图 用户 -\u0026gt; openvpn:通过公网连接openvpn openvpn-\u0026gt;openvpn:下发IP地址，设置动态权限 openvpn-\u0026gt;用户:完成连接 {% endplantuml %} 用到的技术 ipset iptables 主要脚本内容 连接脚本 断开脚本 如果在运行的过程中出现脚本权限不足 "],["openvpn-auth（支持企业微信认证\u0026LDAP）","2022年12月12日","/2022/12/13/openvpn-auth%E6%94%AF%E6%8C%81%E4%BC%81%E4%B8%9A%E5%BE%AE%E4%BF%A1%E8%AE%A4%E8%AF%81ldap.html/"," 方案介绍 时序图 openvpn-auth 时序图 其中有两个地方需要修改 : 企业微信的企业ID : 拥有通讯录的企业微信的Secret 代码如下 使用方式 修改 的验证方式，可以吧其他的验证去掉 加解密方式 因为用到了客户端传过来的时候的加密方式，因此两边的加密方式必须一致 "]]